{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_image1(image):\n",
    "    # Load YOLO\n",
    "    net = cv2.dnn.readNet(\"./darknet/yolov3.weights\", \"./darknet/cfg/yolov3.cfg\")\n",
    "\n",
    "    # Load class labels\n",
    "    classes = []\n",
    "    with open(\"./darknet/data/coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Get the image dimensions\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Preprocess the image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # Set the input blob\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Forward pass through the network\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    outputs = net.forward(output_layers)\n",
    "\n",
    "    # Extract bounding box coordinates and class predictions\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    labels = []\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                labels.append(classes[class_id])\n",
    "\n",
    "    # Apply non-maximum suppression to eliminate overlapping bounding boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for i in indices:\n",
    "        # i = i[0]\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = labels[i]\n",
    "        confidence = confidences[i]\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"{label}: {confidence:.2f}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    return image, labels\n",
    "\n",
    "# Test the function\n",
    "# input_image = cv2.imread(\"./image.jpg\")\n",
    "# output_image, detected_labels = process_image1(input_image)\n",
    "\n",
    "# # Display the output image\n",
    "# cv2.imshow(\"Object Detection\", output_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # Print the detected labels\n",
    "# print(\"Detected Labels:\")\n",
    "# for label in detected_labels:\n",
    "#     print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.1.7:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [14/May/2023 18:35:32] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:36:09] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:37:19] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:38:21] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:40:28] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:45:00] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:47:07] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:49:09] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:50:48] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:51:07] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:51:34] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:55:46] \"POST /process-image1 HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [14/May/2023 18:55:52] \"POST /process-image1 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, send_file, jsonify\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientDetModel\n",
    "app = Flask(__name__)\n",
    "\n",
    "# model = tf.keras.applications.MobileNetV2(weights='imagenet')\n",
    "# model = tf.keras.applications.EfficientNetB0(weights='imagenet')\n",
    "def detect_edges(img):\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    return edges\n",
    "\n",
    "\n",
    "@app.route('/process-image1', methods=['POST'])\n",
    "def process_image_route():\n",
    "    image_file = request.files.get('image')\n",
    "    image = cv2.imdecode(np.frombuffer(image_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "    image1 = image.copy()\n",
    "\n",
    "    # Process the image\n",
    "    processed_image, detected_labels = process_image1(image1)\n",
    "\n",
    "    # Convert the processed image to JPEG format\n",
    "    ret, jpeg = cv2.imencode('.jpg', processed_image)\n",
    "    encoded_image = jpeg.tobytes()\n",
    "\n",
    "    # Create a response JSON object\n",
    "    response = {\n",
    "        'labels': detected_labels,\n",
    "        'image': base64.b64encode(encoded_image).decode('utf-8')\n",
    "    }\n",
    "\n",
    "    # Return the response as JSON\n",
    "    return jsonify(response)\n",
    "\n",
    "    # Return the encoded image as a response\n",
    "    # return Response(encoded_image, mimetype='image/jpeg')\n",
    "if __name__ == '__main__':\n",
    "    #run app in debug mode on port 5000\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 12 17  9 19  3 22 15 28  1 29 24  0 25]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"./darknet/yolov3.weights\", \"./darknet/cfg/yolov3.cfg\")\n",
    "\n",
    "# Load class labels\n",
    "classes = []\n",
    "with open(\"./darknet/data/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Set the input image and blob dimensions\n",
    "image = cv2.imread(\"./test.jpg\")\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Preprocess the image\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# Set the input blob\n",
    "net.setInput(blob)\n",
    "\n",
    "# Forward pass through the network\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "outputs = net.forward(output_layers)\n",
    "\n",
    "# output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# outputs = net.forward(output_layers)\n",
    "\n",
    "# Extract bounding box coordinates and class predictions\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "for output in outputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# Apply non-maximum suppression to eliminate overlapping bounding boxes\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "# indices = cv2.dnn.NMSBoxes(boxes.tolist(), confidences.tolist(), 0.5, 0.4)\n",
    "# Draw bounding boxes and labels\n",
    "for i in indices:\n",
    "    # i = i[0]\n",
    "    x, y, w, h = boxes[i]\n",
    "    label = classes[class_ids[i]]\n",
    "    confidence = confidences[i]\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.putText(image, f\"{label}: {confidence:.2f}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the output image\n",
    "cv2.imshow(\"Object Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
