{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.ndimage import label\n",
    "\n",
    "def process_image1(image):\n",
    "    # Load YOLO\n",
    "    net = cv2.dnn.readNet(\"./darknet/yolov3.weights\", \"./darknet/cfg/yolov3.cfg\")\n",
    "\n",
    "    # Load class labels\n",
    "    classes = []\n",
    "    with open(\"./darknet/data/coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Get the image dimensions\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Preprocess the image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # Set the input blob\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Forward pass through the network\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    outputs = net.forward(output_layers)\n",
    "\n",
    "    # Extract bounding box coordinates and class predictions\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    labels = []\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                labels.append(classes[class_id])\n",
    "\n",
    "    # Apply non-maximum suppression to eliminate overlapping bounding boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for i in indices:\n",
    "        # i = i[0]\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = labels[i]\n",
    "        confidence = confidences[i]\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"{label}: {confidence:.2f}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    return image, labels\n",
    "def perform_canny_edge_detection(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Return the edges image\n",
    "    return edges\n",
    "\n",
    "def apply_feature_selection(edge_image, min_distance=10, threshold_abs=5, area_threshold=50):\n",
    "    # Find local peaks in the edge image\n",
    "    coordinates = peak_local_max(edge_image, min_distance=min_distance, threshold_abs=threshold_abs)\n",
    "    \n",
    "    # Create a binary mask for the detected features\n",
    "    features_mask = np.zeros_like(edge_image, dtype=bool)\n",
    "    features_mask[tuple(coordinates.T)] = True\n",
    "    \n",
    "    # Label connected regions in the features mask\n",
    "    labeled_features, num_features = label(features_mask)\n",
    "    \n",
    "    # Filter out small regions based on their area\n",
    "    for feature_label in range(1, num_features + 1):\n",
    "        area = np.sum(labeled_features == feature_label)\n",
    "        if area < area_threshold:\n",
    "            labeled_features[labeled_features == feature_label] = 0\n",
    "    \n",
    "        # Convert the labeled features back to an image\n",
    "    selected_features_image = labeled_features.astype(np.uint8) * 255\n",
    "    \n",
    "    # Return the selected features image\n",
    "    return selected_features_image\n",
    "# Test the function\n",
    "# input_image = cv2.imread(\"./image.jpg\")\n",
    "# output_image, detected_labels = process_image1(input_image)\n",
    "\n",
    "# # Display the output image\n",
    "# cv2.imshow(\"Object Detection\", output_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # Print the detected labels\n",
    "# print(\"Detected Labels:\")\n",
    "# for label in detected_labels:\n",
    "#     print(label)\n",
    "###################################\n",
    "# image=cv2.imread(\"./test.jpg\")\n",
    "# edges = perform_canny_edge_detection(image)\n",
    "# #show the original image and the edge detected image\n",
    "# selected= apply_feature_selection(edges)\n",
    "# # print(selected)\n",
    "# cv2.imshow(\"Original Image\", image)\n",
    "# cv2.imshow(\"Edge Detected Image\", edges)\n",
    "# cv2.imshow(\"Selected Features\", selected)\n",
    "# # cv2.imshow(\"Selected Features\", selected.astype(np.uint8) * 255)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.1.7:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, send_file, jsonify\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientDetModel\n",
    "app = Flask(__name__)\n",
    "\n",
    "# model = tf.keras.applications.MobileNetV2(weights='imagenet')\n",
    "# model = tf.keras.applications.EfficientNetB0(weights='imagenet')\n",
    "def detect_edges(img):\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    return edges\n",
    "\n",
    "\n",
    "@app.route('/process-image1', methods=['POST'])\n",
    "def process_image_route():\n",
    "    image_file = request.files.get('image')\n",
    "    image = cv2.imdecode(np.frombuffer(image_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "    image1 = image.copy()\n",
    "\n",
    "    # Process the image\n",
    "    processed_image, detected_labels = process_image1(image1)\n",
    "\n",
    "    # Convert the processed image to JPEG format\n",
    "    ret, jpeg = cv2.imencode('.jpg', processed_image)\n",
    "    encoded_image = jpeg.tobytes()\n",
    "\n",
    "    # Create a response JSON object\n",
    "    response = {\n",
    "        'labels': detected_labels,\n",
    "        'image': base64.b64encode(encoded_image).decode('utf-8')\n",
    "    }\n",
    "\n",
    "    # Return the response as JSON\n",
    "    return jsonify(response)\n",
    "\n",
    "    # Return the encoded image as a response\n",
    "    # return Response(encoded_image, mimetype='image/jpeg')\n",
    "if __name__ == '__main__':\n",
    "    #run app in debug mode on port 5000\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
